import os
import streamlit as st
import sys
import platform

# âœ… ë¬´ì¡°ê±´ ì²« Streamlit ëª…ë ¹ì–´
st.set_page_config(
    page_title="KAIST ê·œì • ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# SQLite ë²„ì „ ë¬¸ì œ í•´ê²° (Streamlit Cloudìš©)
if "streamlit" in sys.modules and platform.system() == "Linux":
    __import__('pysqlite3')
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import time
import shutil
import traceback
from tenacity import retry, stop_after_attempt, wait_fixed
import openai
import httpx
import ssl
import urllib3
import json
import re
from dotenv import load_dotenv
# .env íŒŒì¼ ë¡œë“œ
load_dotenv()
# ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”
DEBUG_MODE = False

# SSL ê²€ì¦ ë¹„í™œì„±í™”
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
ssl._create_default_https_context = ssl._create_unverified_context

# LangChain ì»´í¬ë„ŒíŠ¸ ì„í¬íŠ¸
try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    from langchain_community.vectorstores import Chroma
    from langchain.chains import RetrievalQA
    from langchain_teddynote.document_loaders import HWPLoader
    from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
    from langchain.chains.question_answering import load_qa_chain
    from langchain.chains import ConversationalRetrievalChain
    from langchain.memory import ConversationBufferMemory
except ImportError as e:
    st.error(f"í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    st.info("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
    st.code("pip install langchain langchain-openai langchain-community chromadb langchain-teddynote")
    st.stop()

# ë””ë ‰í† ë¦¬ ì„¤ì •
HWP_DIR = os.path.join(os.path.dirname(__file__), 'data')
CHROMA_DIR = os.path.join(os.path.dirname(__file__), 'chroma_db')
os.makedirs(HWP_DIR, exist_ok=True)
os.makedirs(CHROMA_DIR, exist_ok=True)

# í™˜ê²½ êµ¬ë¶„ í•¨ìˆ˜
def is_streamlit_cloud():
    # Streamlit Cloud(ë¦¬ëˆ…ìŠ¤) í™˜ê²½ì—ì„œëŠ” secrets.tomlì´ ì¡´ì¬
    return platform.system() == "Linux" and hasattr(st, "secrets") and "OPENAI_API_KEY" in st.secrets

if is_streamlit_cloud():
    openai.api_key = st.secrets["OPENAI_API_KEY"]
    openai.api_base = st.secrets.get("OPENAI_API_BASE", "https://api.openai.com/v1")
    OPENAI_MODEL = st.secrets.get("OPENAI_MODEL", "gpt-4.1-mini")
    OPENAI_EMBEDDING_MODEL = st.secrets.get("OPENAI_EMBEDDING_MODEL", "text-embedding-ada-002")
else:
    openai.api_key = os.environ.get("OPENAI_API_KEY", "")
    openai.api_base = os.environ.get("OPENAI_API_BASE", "https://api.openai.com/v1")
    OPENAI_MODEL = os.environ.get("OPENAI_MODEL", "openai.gpt-4.1-mini-2025-04-14")
    OPENAI_EMBEDDING_MODEL = os.environ.get("OPENAI_EMBEDDING_MODEL", "azure.text-embedding-3-large")

# API í‚¤ í™•ì¸
if not openai.api_key:
    st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    st.info("Streamlit Cloudì˜ Settings > Secretsì—ì„œ OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜, ë¡œì»¬ì—ì„œëŠ” .env íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”.")
    st.stop()

# CSS - ìµœìƒë‹¨ì— ë°°ì¹˜í•˜ì—¬ ë¨¼ì € ì ìš©ë˜ë„ë¡ í•¨
st.markdown("""
<style>
/* ì „ì²´ ì•± ìŠ¤íƒ€ì¼ë§ */
.stApp {
    background-color: white;
    font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, Roboto, 'Helvetica Neue', 'Segoe UI', 'Apple SD Gothic Neo', 'Noto Sans KR', sans-serif;
}

/* í—¤ë” ì»¨í…Œì´ë„ˆ - ìƒë‹¨ ê³ ì • */
.header-container {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    z-index: 999;
    background: white;
    padding: 1rem 2rem;
    border-bottom: 1px solid #e5e7eb;
    box-shadow: 0 2px 5px rgba(0,0,0,0.05);
}

/* íƒ€ì´í‹€ ì»¨í…Œì´ë„ˆ ìŠ¤íƒ€ì¼ë§ */
.title-container {
    display: flex;
    align-items: center;
    padding-bottom: 1rem;
}

/* ë©”ì¸ íƒ€ì´í‹€ ìŠ¤íƒ€ì¼ë§ */
.main-title {
    color: #0a1c3e;
    font-size: 2.2rem !important;
    font-weight: 700 !important;
    margin: 0;
    padding: 0;
    line-height: 1.2;
    letter-spacing: -0.025em;
    background: linear-gradient(90deg, #1e3a8a, #3b82f6);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
}

/* ì„œë¸Œíƒ€ì´í‹€ ìŠ¤íƒ€ì¼ë§ */
.subtitle {
    color: #4b5563 !important;
    font-size: 1.1rem !important;
    margin-top: 0.25rem;
    font-weight: 400;
}

/* ì±„íŒ… ì˜ì—­ ì»¨í…Œì´ë„ˆ - ë…ë¦½ì  ìŠ¤í¬ë¡¤ */
.message-container {
    height: auto;
    overflow-y: visible;
    padding: 1rem;
    margin-top: 20px;
    padding-bottom: 150px; /* ì…ë ¥ì°½ ê³ ë ¤ */
}

/* ì‚¬ì´ë“œë°” ìŠ¤íƒ€ì¼ë§ */
.css-1d391kg {
    background-color: #ffffff;
    padding: 1rem;
    border-right: 1px solid #e9ecef;
}

/* ì‚¬ì´ë“œë°” í—¤ë” */
.sidebar .block-container {
    padding-top: 1rem;
}

/* ì±„íŒ… ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ */
.stChatMessage {
    background-color: white;
    border-radius: 15px;
    padding: 1rem;
    margin: 0.5rem 0;
    box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    width: auto !important;
    max-width: none !important;
    min-height: auto !important;
    max-height: none !important;
    overflow-y: visible;
}

/* ì‚¬ìš©ì ë©”ì‹œì§€: ìš°ì¸¡ ì •ë ¬ */
.stChatMessage[data-role="user"] {
    background: linear-gradient(45deg, #E8F0FE, #F8F9FA);
    border-bottom-right-radius: 5px;
    min-height: auto;
    max-width: none !important;
    width: auto !important;
    margin-left: auto !important;
    margin-right: 0 !important;
    box-shadow: 0 2px 5px rgba(30,58,138,0.08);
}

/* ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€: ì¢Œì¸¡ ì •ë ¬ */
.stChatMessage[data-role="assistant"] {
    background: white;
    border-bottom-left-radius: 5px;
    min-height: auto;
    max-width: none !important;
    width: auto !important;
    margin-right: auto !important;
    margin-left: 0 !important;
    box-shadow: 0 2px 5px rgba(30,58,138,0.04);
}

/* ì±„íŒ… ì…ë ¥ í•„ë“œ - í•­ìƒ í•˜ë‹¨ì— ê³ ì • */
.stChatInputContainer {
    position: fixed;
    bottom: 0;
    left: 350px; /* ì‚¬ì´ë“œë°” ë„ˆë¹„ë§Œí¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ */
    right: 0;
    z-index: 100;
    background: white;
    padding: 1rem 2rem;
    border-top: 1px solid rgba(0,0,0,0.1);
    box-shadow: 0 -4px 10px rgba(0,0,0,0.03);
}

/* ì…ë ¥ì°½ ìì²´ ë†’ì´/í°íŠ¸/íŒ¨ë”© */
.stChatInput textarea, .stChatInput input {
    min-height: 100px !important;
    font-size: 1.0rem !important;
    padding: 0.8rem 1rem !important;
    border-radius: 16px !important;
    border: 2px solid #E8F0FE !important;
}

/* ì±„íŒ… ì•„ë°”íƒ€ */
.stChatAvatar {
    width: 40px !important;
    height: 40px !important;
    border-radius: 50% !important;
    margin-right: 10px !important;
}

/* ìŠ¤í”¼ë„ˆì™€ ë¡œë”© ìƒíƒœ ìŠ¤íƒ€ì¼ë§ - ì¼ê´€ëœ UIë¥¼ ìœ„í•¨ */
.stSpinner {
    margin-top: 2rem;
    margin-bottom: 2rem;
}

/* ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ */
.stButton button {
    background-color: White;
    color: white;
    border: none;
    padding: 0.5rem 1rem;
    border-radius: 8px;
    font-weight: 600;
    transition: all 0.3s ease;
}

/* ì´ˆê¸°í™” ë²„íŠ¼ */
button[kind="secondary"] {
    background-color: #FF6B6B !important;
}

.stButton button:hover {
    opacity: 0.9;
}

/* í™•ì¥ íŒ¨ë„ ìŠ¤íƒ€ì¼ë§ */
.streamlit-expanderHeader {
    background-color: #f8fafc;
    border-radius: 8px;
    padding: 1rem;
    font-weight: 600;
}

/* ìŠ¤í¬ë¡¤ë°” ìŠ¤íƒ€ì¼ë§ */
::-webkit-scrollbar {
    width: 8px;
    height: 8px;
}

::-webkit-scrollbar-track {
    background: #f1f1f1;
    border-radius: 4px;
}

::-webkit-scrollbar-thumb {
    background: #2563eb;
    border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
    background: #1e3a8a;
}

/* Streamlit ìš”ì†Œ ì¡°ì • */
.css-1544g2n.e1fqkh3o4 {
    padding-top: 0;
}

/* ì‚¬ì´ë“œë°” ë„“ì´ ì¡°ì ˆ */
section[data-testid="stSidebar"] {
    width: 350px;
    position: fixed;
    top: 0;
    left: 0;
    bottom: 0;
    overflow-y: auto;
    background-color: #ffffff;
    padding: 1rem;
    border-right: 1px solid #e9ecef;
}

/* ì‚¬ì´ë“œë°” ë‚´ ëª¨ë“  ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ - ë” ê°•ë ¥í•œ ì„ íƒì ì‚¬ìš© */
section[data-testid="stSidebar"] .stButton > button {
    background-color: white !important;
    color: #1e3a8a !important;
    border: 1px solid #e5e7eb !important;
    text-align: left !important;
    justify-content: flex-start !important;
    border-radius: 8px !important;
    padding: 0.5rem 1rem !important;
    margin-bottom: 0.5rem !important;
    width: 100% !important;
    font-size: 0.85rem !important;
    font-weight: 400 !important;
    box-shadow: none !important;
    transition: all 0.2s ease;
}

section[data-testid="stSidebar"] .stButton > button:hover {
    border-color: #2563eb !important;
    color: #1e40af !important;
    background-color: #f8fafc !important;
}

/* ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ */
.example-questions .stButton > button {
    background-color: white !important;
    color: #1e3a8a !important;
}

/* ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ - í˜¸ë²„ ìƒíƒœ */
.example-questions .stButton > button:hover {
    border-color: #2563eb !important;
    color: #1e40af !important;
    background-color: #f8fafc !important;
}

/* ì‚¬ì´ë“œë°”ì˜ ë²„íŠ¼ ì»¨í…Œì´ë„ˆë¥¼ example-questions í´ë˜ìŠ¤ë¡œ ì§€ì • */
.example-questions .stButton > button {
    background-color: white !important;
    color: #1e3a8a !important;
}

/* ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ - í˜¸ë²„ ìƒíƒœ */
.example-questions .stButton > button:hover {
    border-color: #2563eb !important;
    color: #1e40af !important;
    background-color: #f8fafc !important;
}

/* ì¶”ê°€ ì—¬ë°± ì œê±° */
.block-container {
    padding-top: 0 !important;
    max-width: 100% !important;
}

/* main content ì˜ì—­ */
.main .block-container {
    padding-left: 2rem;
    padding-right: 2rem;
    padding-top: 0 !important;
    max-width: 100% !important;
    margin-left: 350px; /* ì‚¬ì´ë“œë°” ë„ˆë¹„ë§Œí¼ ì—¬ë°± */
}

/* ë©”ì‹œì§€ ì±„íŒ… ì»¨í…Œì´ë„ˆë¥¼ ìœ„í•œ ì¼ê´€ëœ ê³µê°„ */
.message-container {
    min-height: 600px;
    padding-bottom: 150px;
}

/* ì‚¬ì´ë“œë°” í—¤ë” ìŠ¤íƒ€ì¼ë§ */
.sidebar-header {
    padding: 0;
    margin: 0;
    text-align: center;
}

.sidebar-header img {
    margin: 0 auto 0.5rem;
    display: block;
}

.sidebar-header .main-title {
    font-size: 1.8rem !important;
    text-align: center;
    margin-top: 0.2rem;
    margin-bottom: 0.25rem;
}

.sidebar-header .subtitle {
    font-size: 0.9rem !important;
    text-align: center;
    margin: 0;
}

.sidebar-divider {
    margin: 1rem 0;
    border: 0;
    border-top: 1px solid #e5e7eb;
}

/* í—¤ë” ì»¨í…Œì´ë„ˆ - ì œê±° (ì‚¬ì´ë“œë°”ë¡œ ì´ë™) */
.header-container {
    display: none;
}

/* ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ - ìƒë‹¨ ì—¬ë°± ì œê±° */
.message-container {
    height: auto;
    overflow-y: visible;
    padding: 1rem;
    margin-top: 20px;
    padding-bottom: 150px; /* ì…ë ¥ì°½ ê³ ë ¤ */
}

/* ì±„íŒ… ì…ë ¥ í•„ë“œ - ìœ„ì¹˜ ì¡°ì • */
.stChatInputContainer {
    position: fixed;
    bottom: 0;
    left: 350px; /* ì‚¬ì´ë“œë°” ë„ˆë¹„ë§Œí¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ */
    right: 0;
    z-index: 100;
    background: white;
    padding: 1rem 2rem;
    border-top: 1px solid rgba(0,0,0,0.1);
    box-shadow: 0 -4px 10px rgba(0,0,0,0.03);
}

section[data-testid="stSidebar"] .block-container {
    padding-top: 0 !important;
    margin-top: 0 !important;
}
section[data-testid="stSidebar"] {
    padding-top: 0 !important;
    margin-top: 0 !important;
}

/* ì‚¬ì´ë“œë°” ìƒë‹¨ ì—¬ë°± ì™„ì „ ì œê±° - ìµœìš°ì„  ì ìš© */
section[data-testid="stSidebar"] {
    padding-top: 0 !important;
    margin-top: 0 !important;
}

section[data-testid="stSidebar"] > div {
    padding-top: 0 !important;
    margin-top: 0 !important;
}

section[data-testid="stSidebar"] .block-container {
    padding-top: 0 !important;
    margin-top: 0 !important;
}

section[data-testid="stSidebar"] .element-container:first-child {
    margin-top: 0 !important;
    padding-top: 0 !important;
}

/* ì‚¬ì´ë“œë°” ë‚´ë¶€ ëª¨ë“  divì— ìƒë‹¨ ì—¬ë°± ì œê±° */
section[data-testid="stSidebar"] div:first-child {
    margin-top: 0 !important;
    padding-top: 0 !important;
}

section[data-testid="stSidebar"] .stMarkdown {
    margin-top: 0 !important;
    padding-top: 0 !important;
}

section[data-testid="stSidebar"] .sidebar-header {
    margin-top: 0 !important;
    padding-top: 0 !important;
}
</style>
""", unsafe_allow_html=True)

# ë©”ì‹œì§€ ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! KAIST ê·œì •ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"}
    ]

# ëŒ€í™” ê¸°ë¡ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ì˜ˆì‹œ ì§ˆë¬¸ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ í•¨ìˆ˜
def add_user_message(message):
    # ì¤‘ë³µ ë©”ì‹œì§€ ì²´í¬: ê°™ì€ ë‚´ìš©ì˜ user ë©”ì‹œì§€ê°€ ì´ë¯¸ ë§ˆì§€ë§‰ì— ìˆìœ¼ë©´ ì¶”ê°€í•˜ì§€ ì•ŠìŒ
    if (len(st.session_state.messages) > 0 and
            st.session_state.messages[-1]["role"] == "user" and
            st.session_state.messages[-1]["content"] == message):
        return False
    
    # ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": message})
    return True

# í›„ì† ì§ˆë¬¸ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ ìˆ˜ì •
def extract_follow_up_questions(text):
    """
    ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ì—ì„œ í›„ì† ì§ˆë¬¸ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ê´€ë ¨ ì§ˆë¬¸ ì„¹ì…˜ì—ì„œ ì§ˆë¬¸ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    """
    # ë””ë²„ê¹…ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì¶œë ¥ (DEBUG_MODEê°€ Trueì¸ ê²½ìš°)
    if DEBUG_MODE:
        print(f"ë‹µë³€ í…ìŠ¤íŠ¸ í™•ì¸: {text[:200]}...")
    
    # ë§ˆí¬ë‹¤ìš´ íŒ¨í„´ ì²˜ë¦¬ - ìƒˆë¡œìš´ í˜•ì‹ì— ë§ê²Œ ì—…ë°ì´íŠ¸
    patterns = [
        # ë§ˆí¬ë‹¤ìš´ í—¤ë” í˜•ì‹ (ìƒˆë¡œìš´ ì§€ì • í˜•ì‹)
        r"##\s*ì¶”ì²œ\s*ì§ˆë¬¸\s*\n([\s\S]*?)(?=##|$)",
        # ë§ˆí¬ë‹¤ìš´ í—¤ë” í˜•ì‹ (ë‹¤ë¥¸ ë³€í˜•)
        r"##\s*ê´€ë ¨\s*ì§ˆë¬¸\s*\n([\s\S]*?)(?=##|$)",
        # ì´ì „ í˜•ì‹ë“¤ê³¼ì˜ í˜¸í™˜ì„± ìœ ì§€
        r"###?\s*ì¶”ì²œ\s*ì§ˆë¬¸\s*:?\n([\s\S]*?)(?=###|$)",
        r"###?\s*ê´€ë ¨\s*ì§ˆë¬¸\s*:?\n([\s\S]*?)(?=###|$)",
        # ì¼ë°˜ í…ìŠ¤íŠ¸ íŒ¨í„´ (ë°±ì—…)
        r"ì¶”ì²œ\s*ì§ˆë¬¸\s*:?\n([\s\S]*?)(?=\n\n|$)"
    ]
    
    questions_section = ""
    for pattern in patterns:
        match = re.search(pattern, text)
        if match:
            questions_section = match.group(1).strip()
            break
    
    if not questions_section:
        # ë””ë²„ê¹…ìš© ì „ì²´ í…ìŠ¤íŠ¸ì˜ ì¼ë¶€ ì¶œë ¥
        if DEBUG_MODE:
            debug_text = text[:200] + "..." if len(text) > 200 else text
            print(f"DEBUG: í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ ì‹œì‘ ë¶€ë¶„: {debug_text}")
            print(f"DEBUG: ì „ì²´ í…ìŠ¤íŠ¸: {text}")
        
        # ëŒ€ì•ˆ: ê°„ë‹¨í•œ ìì²´ ìƒì„± ì§ˆë¬¸ ì‚¬ìš© (LLM í˜¸ì¶œ ì—†ì´)
        return [
            "ë‹¤ë¥¸ ê´€ë ¨ ê·œì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì´ ë‚´ìš©ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ì´ ê·œì •ì˜ ì˜ˆì™¸ì‚¬í•­ì´ ìˆë‚˜ìš”?"
        ]
    
    # ë””ë²„ê¹…: ì°¾ì€ ì§ˆë¬¸ ì„¹ì…˜ ì¶œë ¥
    if DEBUG_MODE:
        print(f"DEBUG: ì°¾ì€ ì§ˆë¬¸ ì„¹ì…˜: {questions_section}")
    
    # ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ í•­ëª© ì¶”ì¶œ (1. 2. 3. ë“±ì˜ í˜•ì‹)
    numbered_items = re.findall(r'^\s*\d+\.?\s*(.*?)$', questions_section, re.MULTILINE)
    if numbered_items and len(numbered_items) >= 2:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ ë²ˆí˜¸ ë§¤ê¹€ í•­ëª©ì´ ìˆìœ¼ë©´
        # ë””ë²„ê¹…: ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ í•­ëª© í™•ì¸
        if DEBUG_MODE:
            print(f"DEBUG: ë²ˆí˜¸ ë§¤ê¹€ í•­ëª© ë°œê²¬: {numbered_items}")
        
        # ê° í•­ëª© ì •ë¦¬ (ëŒ€ê´„í˜¸ ë“± ì œê±°)
        questions = []
        for item in numbered_items:
            # ëŒ€ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë‚´ìš© ì¶”ì¶œ ë˜ëŠ” ê·¸ëƒ¥ í•­ëª© ì‚¬ìš©
            clean_item = re.sub(r'^\[(.*)\]$', r'\1', item.strip())
            if clean_item and len(clean_item) > 5:
                questions.append(clean_item)
        
        if len(questions) >= 2:  # ì˜ë¯¸ ìˆëŠ” ì§ˆë¬¸ì´ 2ê°œ ì´ìƒ ì¶”ì¶œëìœ¼ë©´ ì‚¬ìš©
            return questions
    
    # ë²ˆí˜¸ ë§¤ê¹€ì´ ì‹¤íŒ¨í•˜ë©´ ì¼ë°˜ì ì¸ ë°©ë²•ìœ¼ë¡œ ì¶”ì¶œ ì‹œë„
    questions = []
    for line in questions_section.split("\n"):
        # HTML íƒœê·¸ ì œê±°
        line = re.sub(r'<[^>]*>', '', line)
        # ì¤„ì—ì„œ ì•ë¶€ë¶„ì˜ ë¶ˆë¦¿, ë²ˆí˜¸, ëŒ€ì‹œ ë“± ì œê±°
        clean_line = re.sub(r"^[\s\-â€“â€¢*0-9.)\]]*\s*", "", line).strip()
        # ëŒ€ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ ë˜ëŠ” ì „ì²´ ë¼ì¸ ì‚¬ìš©
        if '[' in clean_line and ']' in clean_line:
            bracket_content = re.search(r'\[(.*?)\]', clean_line)
            if bracket_content:
                clean_line = bracket_content.group(1).strip()
        
        if clean_line and not clean_line.startswith("ê´€ë ¨í•´ì„œ") and len(clean_line) > 5:
            questions.append(clean_line)
    
    # ë””ë²„ê¹…: ì¶”ì¶œëœ ì§ˆë¬¸ í™•ì¸
    if DEBUG_MODE and questions:
        print(f"DEBUG: ì¶”ì¶œëœ ì§ˆë¬¸: {questions}")
    
    # ì§ˆë¬¸ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©
    if not questions:
        return [
            "ë‹¤ë¥¸ ê´€ë ¨ ê·œì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”",
            "ì´ ë‚´ìš©ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            "ì´ ê·œì •ì˜ ì˜ˆì™¸ì‚¬í•­ì´ ìˆë‚˜ìš”?"
        ]
    
    return questions

# í›„ì† ì§ˆë¬¸ ì„¹ì…˜ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜ ì—…ë°ì´íŠ¸
def remove_follow_up_questions_section(text):
    """
    ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ì—ì„œ í›„ì† ì§ˆë¬¸ ì„¹ì…˜ì„ ì œê±°í•˜ëŠ” í•¨ìˆ˜
    ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì§€ì›
    """
    # ë§ˆí¬ë‹¤ìš´ íŒ¨í„´ë“¤ - ìƒˆë¡œìš´ í˜•ì‹ í¬í•¨
    patterns = [
        r"##\s*ì¶”ì²œ\s*ì§ˆë¬¸\s*\n[\s\S]*?(?=##|$)",  # ìƒˆ í˜•ì‹ (##)
        r"##\s*ê´€ë ¨\s*ì§ˆë¬¸\s*\n[\s\S]*?(?=##|$)",  # ìƒˆ í˜•ì‹ (##)
        r"####\s*ì¶”ì²œ\s*ì§ˆë¬¸\s*\n[\s\S]*?(?=####|$)",  # ìƒˆ í˜•ì‹ (####)
        r"####\s*ê´€ë ¨\s*ì§ˆë¬¸\s*\n[\s\S]*?(?=####|$)",  # ìƒˆ í˜•ì‹ (####)
        r"###?\s*ì¶”ì²œ\s*ì§ˆë¬¸\s*:?\n[\s\S]*?(?=###|$)",  # ê¸°ì¡´ í˜•ì‹ (###)
        r"###?\s*ê´€ë ¨\s*ì§ˆë¬¸\s*:?\n[\s\S]*?(?=###|$)",  # ê¸°ì¡´ í˜•ì‹ (###)
        r"ì¶”ì²œ\s*ì§ˆë¬¸\s*:?\n[\s\S]*?(?=\n\n|$)"  # ì¼ë°˜ í…ìŠ¤íŠ¸ í˜•ì‹
    ]
    
    # ì›ë³¸ í…ìŠ¤íŠ¸ ì €ì¥
    original_text = text
    
    # ê° íŒ¨í„´ ì ìš©
    result = text
    for pattern in patterns:
        result = re.sub(pattern, "", result)
    
    # ë””ë²„ê¹… - í…ìŠ¤íŠ¸ ë³€ê²½ í™•ì¸
    if DEBUG_MODE and original_text != result:
        print(f"DEBUG: ì§ˆë¬¸ ì„¹ì…˜ ì œê±°ë¨. ì›ë³¸ ê¸¸ì´: {len(original_text)}, ì²˜ë¦¬ í›„ ê¸¸ì´: {len(result)}")
    
    return result.strip()

# ì‚¬ì´ë“œë°” ì˜ˆì‹œ ì§ˆë¬¸
with st.sidebar:
    # ì‚¬ì´ë“œë°” ìƒë‹¨ì— ë¡œê³ ì™€ íƒ€ì´í‹€ ë°°ì¹˜
    st.markdown('<div class="sidebar-header">', unsafe_allow_html=True)
    st.image("kaistlogo.png", width=150)
    st.markdown('<h1 class="main-title">KAIST ChatBot</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">KAIST ê·œì •ì— ëŒ€í•œ ì§ˆë¬¸ ë° ë‹µë³€</p>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)
    
    # êµ¬ë¶„ì„  ì¶”ê°€
    st.markdown('<hr class="sidebar-divider">', unsafe_allow_html=True)
    
    with st.expander("âš™ï¸ ì„¤ì •", expanded=False):
        st.markdown("#### ğŸ“š ë²¡í„°DB ì„¤ì •")
        force_rebuild = st.checkbox("ë²¡í„°DB ê°•ì œ ì¬ìƒì„±", value=False)
        if force_rebuild and os.path.exists(CHROMA_DIR):
            if st.button("ë²¡í„°DB ì¬ìƒì„±", help="ê¸°ì¡´ ë²¡í„°DBë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤", key="rebuild_btn"):
                shutil.rmtree(CHROMA_DIR, ignore_errors=True)
                if "retriever" in st.session_state:
                    del st.session_state.retriever
                st.success("âœ¨ ë²¡í„°DBê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨í•˜ì—¬ ì¬ìƒì„±ì„ ì‹œì‘í•˜ì„¸ìš”.")
                st.rerun()
    
    st.markdown("### ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸")
    
    # ì§ì ‘ HTMLê³¼ CSSë¡œ ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§
    st.markdown("""
    <style>
    .custom-button {
        background-color: white;
        color: #1e3a8a;
        border: 1px solid #e5e7eb;
        border-radius: 8px;
        padding: 8px 12px;
        margin-bottom: 8px;
        width: 100%;
        text-align: left;
        font-size: 14px;
        cursor: pointer;
        transition: all 0.2s;
    }
    .custom-button:hover {
        border-color: #2563eb;
        background-color: #f8fafc;
    }
    </style>
    """, unsafe_allow_html=True)
    
    example_questions = [
        "ë²•ì¸ì¹´ë“œë¡œ ì§€ì¶œí•œ ê¸ˆì•¡ì€ ì–´ë–¤ ì¦ë¹™ì„œë¥˜ê°€ í•„ìš”í•˜ê³ , ì •ì‚° ê¸°í•œì€ ì–¸ì œê¹Œì§€ì¸ê°€ìš”?",
        "ì¶œì¥ ì¤‘ ì‹ë¹„ì™€ ìˆ™ë°•ë¹„ëŠ” ê°ê° ì–¼ë§ˆê¹Œì§€ ì¸ì •ë˜ë©°, ê¸°ì¤€ ê¸ˆì•¡ì„ ì´ˆê³¼í•˜ë©´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ìƒí’ˆê¶Œì„ êµ¬ë§¤í•œ ê²½ìš°, ë¹„ìš© ì²˜ë¦¬ ì‹œ ì–´ë–¤ ì œí•œì´ ìˆê³  ì–´ë–¤ ì„œë¥˜ê°€ í•„ìš”í•˜ë‚˜ìš”?",
        "ê³¼ì„¸ í•­ëª©ê³¼ ë¹„ê³¼ì„¸ í•­ëª©ì„ êµ¬ë¶„í•˜ëŠ” ê¸°ì¤€ì€ ë¬´ì—‡ì´ë©°, ëŒ€í‘œì ì¸ ì˜ˆì‹œëŠ” ì–´ë–¤ ê²Œ ìˆë‚˜ìš”?",
        "ê°™ì€ í•­ëª©ìœ¼ë¡œ ì¤‘ë³µ ì§€ì¶œì´ ë°œìƒí•œ ê²½ìš° ì–´ë–»ê²Œ ì²˜ë¦¬ë˜ê³ , í™˜ìˆ˜ ëŒ€ìƒì´ ë  ìˆ˜ ìˆë‚˜ìš”?",
        "ê°•ì˜ë£Œë‚˜ ì—°êµ¬ìˆ˜ë‹¹ ë“± ì¸ê±´ë¹„ í•­ëª©ì€ ì–´ë–¤ ì†Œë“ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜ë˜ë©°, ì„¸ìœ¨ì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "ì‚¬ì  ìš©ë„ ë˜ëŠ” ê°€ì¡± ëª…ì˜ ê³„ì¢Œë¡œ ì§€ê¸‰ëœ ì§€ì¶œì€ ì–´ë–¤ ì ˆì°¨ë¡œ í™•ì¸ë˜ë©°, ë¬¸ì œê°€ ë  ê²½ìš° ì¡°ì¹˜ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "ì—°ë§ ë˜ëŠ” íšŒê³„ì—°ë„ ë§ì— ëª°ì•„ì„œ ì§€ì¶œí•œ ê²½ìš° ê·œì •ìƒ ë¬¸ì œê°€ ë  ìˆ˜ ìˆë‚˜ìš”?",
        "ë¹„ìš© ì§€ì¶œ ì‹œ ì¹´ë“œ ì‚¬ìš©ì´ í•„ìˆ˜ì¸ê°€ìš”, ì•„ë‹ˆë©´ í˜„ê¸ˆ ì •ì‚°ë„ ê°€ëŠ¥í•œê°€ìš”?",
        "ì§€ì¶œ ì˜ˆì •ì¼ ì „ì— ì„ ì§€ê¸‰ì´ í•„ìš”í•œ ê²½ìš° ì–´ë–¤ ì¡°ê±´ê³¼ ì ˆì°¨ë¥¼ ë”°ë¼ì•¼ í•˜ë‚˜ìš”?"
    ]

    # ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ì„ ì»¨í…Œì´ë„ˆë¡œ ê°ì‹¸ì„œ í•œ ë²ˆë§Œ ë Œë”ë§ë˜ë„ë¡ í•¨
    question_container = st.container()
    with question_container:
        for q in example_questions:
            if st.button(q, key=f"btn_{hash(q)}", use_container_width=True):
                if add_user_message(q):
                    st.rerun()

# ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼ì„ ìš°ì¸¡ì— ë°°ì¹˜
if st.session_state.messages and len(st.session_state.messages) > 1:  # ì´ˆê¸° ë©”ì‹œì§€ë§Œ ìˆëŠ” ê²½ìš°ëŠ” ì œì™¸
    col1, col2, col3 = st.columns([6, 1, 1])
    with col3:
        if st.button("ëŒ€í™” ì´ˆê¸°í™”", key="clear_chat"):
            st.session_state.messages = [
                {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! KAIST ê·œì •ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"}
            ]
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ë„ ì´ˆê¸°í™”
            st.session_state.chat_history = []
            st.rerun()

# ì±„íŒ… ì˜ì—­ì— ì¼ê´€ëœ ê³µê°„ ì œê³µ
st.markdown('<div class="message-container">', unsafe_allow_html=True)

# ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ - ê° ë©”ì‹œì§€ëŠ” ì •í™•íˆ í•œ ë²ˆë§Œ í‘œì‹œë¨
for i, message in enumerate(st.session_state.messages):
    # ëª¨ë“  ë©”ì‹œì§€ë¥¼ í‘œì‹œ (ê±´ë„ˆë›°ëŠ” ë©”ì‹œì§€ ì—†ìŒ)
    with st.chat_message(message["role"], avatar="ğŸ§‘â€ğŸ’»" if message["role"] == "user" else "ğŸ¤–"):
        if message["role"] == "assistant":
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ì¸ ê²½ìš° í›„ì† ì§ˆë¬¸ ì„¹ì…˜ ì œê±° í›„ í‘œì‹œ
            clean_content = remove_follow_up_questions_section(message["content"])
            # HTML ë Œë”ë§ í™œì„±í™”
            st.markdown(clean_content, unsafe_allow_html=True)
            
            # ì°¸ê³  ë¬¸ì„œê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í‘œì‹œ (ìƒë‹¨ì— ë°°ì¹˜)
            if message["role"] == "assistant" and "reference_docs" in message and message["reference_docs"]:
                with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ"):
                    for doc_idx, doc in enumerate(message["reference_docs"]):
                        st.markdown(f"**ë¬¸ì„œ {doc_idx+1}**")
                        st.markdown(f"```\n{doc['content']}\n```")
                        if "metadata" in doc and doc["metadata"]:
                            st.markdown(f"*ë©”íƒ€ë°ì´í„°:* {doc['metadata']}")
            
            # ì²« ë²ˆì§¸ í™˜ì˜ ë©”ì‹œì§€(ì¸ë±ìŠ¤ 0)ê°€ ì•„ë‹Œ ê²½ìš°ì—ë§Œ í›„ì† ì§ˆë¬¸ í‘œì‹œ
            if i > 0:  
                # í›„ì† ì§ˆë¬¸ ì¶”ì¶œ ë˜ëŠ” ê¸°ë³¸ ì§ˆë¬¸ ì‚¬ìš©
                follow_up_questions = ["ë‹¤ë¥¸ ê´€ë ¨ ê·œì •ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”", 
                                      "ì´ ë‚´ìš©ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”", 
                                      "ì´ ê·œì •ì˜ ì˜ˆì™¸ì‚¬í•­ì´ ìˆë‚˜ìš”?"]
                
                # ë©”ì‹œì§€ì— í›„ì† ì§ˆë¬¸ì´ ì €ì¥ë˜ì–´ ìˆìœ¼ë©´ ê·¸ê²ƒ ì‚¬ìš©
                if "follow_up_questions" in message and message["follow_up_questions"]:
                    follow_up_questions = message["follow_up_questions"]
                # ì•„ë‹ˆë©´ ë‚´ìš©ì—ì„œ ì¶”ì¶œ
                else:
                    extracted = extract_follow_up_questions(message["content"])
                    if extracted:
                        follow_up_questions = extracted
                
                # í›„ì† ì§ˆë¬¸ ë²„íŠ¼ í‘œì‹œ
                st.write("---")
                st.write("**ë” ì§ˆë¬¸í•´ë³´ì„¸ìš”:**")
                
                # ë²„íŠ¼ì„ ì˜ˆì‹œ ì§ˆë¬¸ê³¼ ë™ì¼í•œ ìŠ¤íƒ€ì¼ë¡œ ì ìš©
                st.markdown("""
                <style>
                /* ì˜ˆì‹œ ì§ˆë¬¸ ë²„íŠ¼ê³¼ ì¼ì¹˜í•˜ëŠ” ìŠ¤íƒ€ì¼ ì ìš© */
                .stButton > button {
                    background-color: white !important;
                    color: #1e3a8a !important;
                    border: 1px solid #e5e7eb !important;
                    text-align: left !important;
                    justify-content: flex-start !important;
                    border-radius: 8px !important;
                    padding: 0.5rem 1rem !important;
                    margin-bottom: 0.5rem !important;
                    font-size: 0.85rem !important;
                    font-weight: 400 !important;
                    box-shadow: none !important;
                    transition: all 0.2s ease;
                }
                
                .stButton > button:hover {
                    border-color: #2563eb !important;
                    color: #1e40af !important;
                    background-color: #f8fafc !important;
                }
                </style>
                """, unsafe_allow_html=True)
                
                # ê° ì§ˆë¬¸ì„ ë²„íŠ¼ìœ¼ë¡œ í‘œì‹œ - Streamlit ë²„íŠ¼ ì‚¬ìš©
                for idx, question in enumerate(follow_up_questions):
                    # ì§ˆë¬¸ ë‚´ìš©ì˜ í•´ì‹œê°’ì„ í¬í•¨í•˜ì—¬ ê³ ìœ í•œ í‚¤ ìƒì„±
                    unique_key = f"follow_up_{i}_{idx}_{abs(hash(question)) % 10000}"
                    if st.button(question, key=unique_key, use_container_width=True):
                        add_user_message(question)
                        st.rerun()
        else:
            # ì‚¬ìš©ì ë©”ì‹œì§€ëŠ” ê·¸ëŒ€ë¡œ í‘œì‹œ
            st.markdown(message["content"])

# ë‹µë³€ë˜ì§€ ì•Šì€ user ë©”ì‹œì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
messages = st.session_state.messages
has_pending_user_message = (
    len(messages) > 1
    and messages[-1]["role"] == "user"
    and (len(messages) == 2 or messages[-2]["role"] == "assistant")
)

# ë‹µë³€ ìƒì„± ë¶€ë¶„
if has_pending_user_message:
    # ë§ˆì§€ë§‰ ì§ˆë¬¸ ë©”ì‹œì§€ëŠ” ì±„íŒ… íˆìŠ¤í† ë¦¬ì—ì„œ ì´ë¯¸ í‘œì‹œë¨, ì—¬ê¸°ì„œëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŒ
    
    # ë‹µë³€ ìƒì„± (UIì— ì§ì ‘ í‘œì‹œí•˜ì§€ ì•Šê³  st.session_state.messagesì—ë§Œ ì¶”ê°€)
    if "retriever" not in st.session_state or "qa" not in st.session_state:
        st.error("ì‹œìŠ¤í…œì´ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        st.session_state.messages.append({
            "role": "assistant", 
            "content": "âŒ ì‹œìŠ¤í…œì´ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "reference_docs": [],
            "follow_up_questions": ["ì‹œìŠ¤í…œ ì¬ì‹œì‘í•˜ê¸°", "ë„ì›€ë§ ë³´ê¸°", "ë¬¸ì„œ í™•ì¸í•˜ê¸°"]
        })
        st.rerun()
    else:
        with st.spinner('ğŸ¤” ë‹µë³€ ìƒì„± ì¤‘...'):
            try:
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ í˜•ì‹ ë³€í™˜ (ConversationalRetrievalChain í˜•ì‹ì— ë§ê²Œ)
                current_question = messages[-1]["content"]
                
                # ê²€ìƒ‰ ê²°ê³¼
                search_docs = st.session_state.retriever.get_relevant_documents(current_question)
                
                # ë‹µë³€ ìƒì„± - ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œìš©
                result = st.session_state.qa({"question": current_question, "chat_history": st.session_state.chat_history})
                answer = result["answer"]
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— í˜„ì¬ ì§ˆë¬¸-ë‹µë³€ ìŒ ì¶”ê°€
                st.session_state.chat_history.append((current_question, answer))
                
                # í›„ì† ì§ˆë¬¸ ìƒì„± - ë‹µë³€ì—ì„œ ì¶”ì¶œ ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
                follow_up_questions = extract_follow_up_questions(answer)
                if not follow_up_questions:
                    # ê¸°ë³¸ í›„ì† ì§ˆë¬¸
                    follow_up_questions = [
                        "ì´ ë‚´ìš©ì„ ë” ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
                        "ê´€ë ¨ ê·œì •ì˜ ì˜ˆì™¸ì‚¬í•­ì´ ìˆë‚˜ìš”?",
                        "ë¹„ìŠ·í•œ ë‹¤ë¥¸ ì‚¬ë¡€ê°€ ìˆì„ê¹Œìš”?"
                    ]
                
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
                if search_docs:
                    # ì°¸ê³  ë¬¸ì„œ ì •ë³´ ì €ì¥ì„ ìœ„í•œ í˜•ì‹ ë³€í™˜
                    reference_docs = []
                    
                    # ê²€ìƒ‰ ë¬¸ì„œ ì •ë³´ ì €ì¥ (ëª¨ë“  ë¬¸ì„œ í¬í•¨)
                    for doc in search_docs:
                        # ë©”íƒ€ë°ì´í„° ì €ì¥
                        metadata = {}
                        if hasattr(doc, 'metadata') and doc.metadata:
                            metadata = doc.metadata
                        
                        # ì°¸ê³  ë¬¸ì„œ ì •ë³´ ì €ì¥
                        reference_docs.append({
                            "content": doc.page_content,
                            "metadata": metadata
                        })
                    
                    # ë©”ì‹œì§€ ì €ì¥ (ì°¸ê³  ë¬¸ì„œ ì •ë³´ í¬í•¨)
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": answer,
                        "reference_docs": reference_docs,
                        "follow_up_questions": follow_up_questions
                    })
                
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
                else:
                    # ì°¸ê³  ë¬¸ì„œ ì—†ì´ ë©”ì‹œì§€ ì €ì¥
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": answer,  # ê²½ê³  ë©”ì‹œì§€ ì—†ì´
                        "reference_docs": [],
                        "follow_up_questions": follow_up_questions
                    })
            
            except Exception as e:
                error_message = f"ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                st.error(error_message)
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": f"âŒ {error_message}",
                    "reference_docs": [],
                    "follow_up_questions": ["ë‹¤ì‹œ ì§ˆë¬¸í•˜ê¸°", "ì‹œìŠ¤í…œ ì¬ì‹œì‘í•˜ê¸°", "ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°"]
                })
                if DEBUG_MODE:
                    with st.expander("ğŸ” ë””ë²„ê·¸ ì •ë³´"):
                        st.code(traceback.format_exc(), language="python")
            
            # ì²˜ë¦¬ í›„ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
            st.rerun()

st.markdown('</div>', unsafe_allow_html=True)

# ì±„íŒ… ì…ë ¥ ì²˜ë¦¬ (ë§ˆì§€ë§‰ì— ë Œë”ë§)
chat_input = st.chat_input("KAIST ê·œì •ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”")
if chat_input:
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™” í™•ì¸
    if "qa" not in st.session_state or "retriever" not in st.session_state:
        st.error("ì‹œìŠ¤í…œì´ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
    else:
        if add_user_message(chat_input):
            st.rerun()

# ë²¡í„°DB ìƒì„±/ë¡œë“œ ë¶€ë¶„ì€ ì—¬ê¸°ì„œ ì²˜ë¦¬
try:
    # ë²¡í„°DBê°€ ì—†ìœ¼ë©´ ìƒì„±, ìˆìœ¼ë©´ ë¡œë“œ
    need_rebuild = force_rebuild or not os.path.exists(CHROMA_DIR) or not os.listdir(CHROMA_DIR)
    
    if need_rebuild:
        docs = []
        for filename in os.listdir(HWP_DIR):
            if filename.endswith('.hwp'):
                try:
                    file_path = os.path.join(HWP_DIR, filename)
                    loader = HWPLoader(file_path)
                    file_docs = loader.load()
                    docs.extend(file_docs)
                except Exception as e:
                    st.error(f"HWP íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({filename}): {str(e)}")
                    continue
        
        if not docs:
            st.error("ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. HWP íŒŒì¼ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            st.stop()
        
        try:
            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
            splits = splitter.split_documents(docs)
        except Exception as e:
            st.error(f"ë¬¸ì„œ ë¶„í•  ì‹¤íŒ¨: {str(e)}")
            st.stop()
        
        try:
            embeddings = OpenAIEmbeddings(
                openai_api_key=openai.api_key,
                openai_api_base=openai.api_base,
                model=OPENAI_EMBEDDING_MODEL
            )
            # ë©”íƒ€ë°ì´í„°ì— ì„ë² ë”© ì •ë³´ ì¶”ê°€
            embedding_info_str = json.dumps({"type": "openai", "provider": "standard", "model": OPENAI_EMBEDDING_MODEL})
            metadata = {"embedding_info": embedding_info_str}
            # ë²¡í„°DB ìƒì„±
            db = Chroma.from_documents(
                documents=splits, 
                embedding=embeddings, 
                persist_directory=CHROMA_DIR,
                collection_metadata={"embedding_info": embedding_info_str}
            )
            db.persist()
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ë¡œ ì €ì¥
            with open(os.path.join(CHROMA_DIR, "embedding_info.json"), "w") as f:
                json.dump({"type": "openai", "provider": "standard", "model": OPENAI_EMBEDDING_MODEL}, f)
            st.success(f"ë²¡í„°DB ìƒì„± ì™„ë£Œ! ì´ {len(splits)}ê°œ ë¬¸ì„œ ì¡°ê°ì´ ì„ë² ë”©ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ë²¡í„°DB ìƒì„± ì‹¤íŒ¨: {str(e)}")
            if DEBUG_MODE:
                import traceback
                st.code(traceback.format_exc(), language="python")
            st.stop()
    else:
        # ì´ì „ì— ì‚¬ìš©í•œ ì„ë² ë”© ì •ë³´ ë¡œë“œ
        embedding_info_path = os.path.join(CHROMA_DIR, "embedding_info.json")
        if os.path.exists(embedding_info_path):
            try:
                with open(embedding_info_path, "r") as f:
                    saved_embedding_info = json.load(f)
                # ì‚¬ìš©ìì—ê²Œ ì €ì¥ëœ ì„ë² ë”© ì •ë³´ ì•ˆë‚´
                if saved_embedding_info["type"] != "openai":
                    st.warning(f"ì£¼ì˜: ë²¡í„°DBëŠ” {saved_embedding_info['type']} ì„ë² ë”©ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìœ¼ë‚˜, í˜„ì¬ openai ì„ë² ë”©ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ê°€ ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.warning(f"ì„ë² ë”© ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ë³¸ ì„ë² ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                saved_embedding_info = None
        else:
            st.warning("ì„ë² ë”© ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë²¡í„°DBë¥¼ ì¬ìƒì„±í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.")
            saved_embedding_info = None
        try:
            embeddings = OpenAIEmbeddings(
                openai_api_key=openai.api_key,
                openai_api_base=openai.api_base,
                model=OPENAI_EMBEDDING_MODEL
            )
            db = Chroma(persist_directory=CHROMA_DIR, embedding_function=embeddings)
        except Exception as e:
            st.error(f"ë²¡í„°DB ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            if DEBUG_MODE:
                import traceback
                st.code(traceback.format_exc(), language="python")
            st.stop()
    try:
        retriever = db.as_retriever(search_kwargs={"k": 3})
        @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
        def create_llm_with_retry():
            return ChatOpenAI(
                temperature=0,
                openai_api_key=openai.api_key,
                openai_api_base=openai.api_base,
                model_name=OPENAI_MODEL,
                request_timeout=60,
                http_client=httpx.Client(verify=False),
            )
        llm = create_llm_with_retry()
        # --- System Prompt ì¶”ê°€ ---
        system_message = SystemMessagePromptTemplate.from_template(
            "ë„ˆëŠ” KAIST íšŒê³„ê·œì •ì— ëŒ€í•œ ì§ˆë¬¸ ë° ë‹µë³€ì„ ì „ë¬¸ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì±—ë´‡ì´ì•¼. í•­ìƒ ì¹œì ˆí•˜ê³  ì •í™•í•˜ê²Œ ë‹µë³€í•´ì¤˜. "
            "ë‹µë³€í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì°¸ê³ í•œ ê·œì • ë‚´ìš©ì´ë‚˜ ì¡°í•­ì„ ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰í•˜ê³ , ê°€ëŠ¥í•œ ê²½ìš° ê·œì •ëª…ì´ë‚˜ ì¡°í•­ ë²ˆí˜¸ë„ í•¨ê»˜ ì–¸ê¸‰í•´ì¤˜. "
            "í™•ì‹¤í•˜ì§€ ì•Šê±°ë‚˜ ê·œì •ì— ëª…ì‹œë˜ì§€ ì•Šì€ ë‚´ìš©ì— ëŒ€í•´ì„œëŠ” 'ì´ ë¶€ë¶„ì€ ê·œì •ì— ëª…í™•íˆ ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤'ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€í•´ì¤˜. ì¶”ì¸¡í•˜ì§€ ë§ê³  ì•Œê³  ìˆëŠ” ë‚´ìš©ë§Œ ë‹µë³€í•´. "
            "ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ì„ í™œìš©í•´ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±í•´ì¤˜:\n\n"
            "ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€ì„ ì—¬ê¸°ì— ì‘ì„±í•´ì¤˜. í•µì‹¬ì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´.\n\n"
            "ê´€ë ¨ ê·œì • ì„¤ëª…ê³¼ ì¶œì²˜ë¥¼ ì—¬ê¸°ì— ê°„ê²°í•˜ê²Œ ëª…ì‹œí•´ì¤˜. ê·œì •ëª…, ì¡°í•­ ë²ˆí˜¸ ë“±ì„ êµ¬ì²´ì ìœ¼ë¡œ í¬í•¨í•´. ì´ ë¶€ë¶„ì€ ì‘ê²Œ ì‘ì„±í•˜ê³  ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ í•´."
        )
        human_message = HumanMessagePromptTemplate.from_template(
            "ë‹¤ìŒ ë§¥ë½ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ë§¥ë½ ì •ë³´ì—ì„œ ì°¸ê³ í•œ ê·œì • ì¶œì²˜ë¥¼ ë°˜ë“œì‹œ ë‹µë³€ì— í¬í•¨í•´ì£¼ì„¸ìš”.\n\n"
            "ë§¥ë½: {context}\n\n"
            "ì§ˆë¬¸: {question}\n\n"
            "ì´ì „ ëŒ€í™”: {chat_history}\n\n"
            "ì°¸ê³ : \n"
            "- ë‹µë³€ì€ ë§ˆí¬ë‹¤ìš´ì„ í™œìš©í•´ ë§Œë“œì„¸ìš”. ì¤‘ìš” ë‚´ìš©ì€ **ë³¼ë“œì²´**ë¡œ ê°•ì¡°í•˜ì„¸ìš”.\n"
            "- ë‹µë³€ì— ê·œì • ì¶œì²˜(ê·œì •ëª…, ì¡°í•­ ë“±)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.\n"
            "- ë‹µë³€ì— ê·œì • ì¶œì²˜(ê·œì •ëª…, ì¡°í•­ ë“±)ëŠ” ê¸°ìš¸ì„ì±„ë¡œ, ì‘ì€ ê¸€ì”¨ë¡œ ë‹µë³€í•˜ì„¸ìš”.\n"
            "- í™•ì‹¤í•˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  ëª…í™•íˆ ëª¨ë¥¸ë‹¤ê³  ë‹µë³€í•˜ì„¸ìš”.\n"
            "- ë‹µë³€ ë§ˆì§€ë§‰ì—ëŠ” ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì§ˆë¬¸ê³¼ ë‹µë³€ ë‚´ìš©ê³¼ ê´€ë ¨ëœ í›„ì† ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”:\n\n"
            "#### ì¶”ì²œ ì§ˆë¬¸\n"
            "1. [ì²« ë²ˆì§¸ ê´€ë ¨ ì§ˆë¬¸]\n"
            "2. [ë‘ ë²ˆì§¸ ê´€ë ¨ ì§ˆë¬¸]\n"
            "3. [ì„¸ ë²ˆì§¸ ê´€ë ¨ ì§ˆë¬¸]"
        )
        prompt = ChatPromptTemplate.from_messages([system_message, human_message])
        
        # ëŒ€í™” ë©”ëª¨ë¦¬ ìƒì„±
        memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True, output_key="answer")
        
        # ConversationalRetrievalChain ìƒì„±
        qa = ConversationalRetrievalChain.from_llm(
            llm=ChatOpenAI(
                temperature=0,
                openai_api_key=openai.api_key,
                openai_api_base=openai.api_base,
                model_name=OPENAI_MODEL,
                request_timeout=60,
                http_client=httpx.Client(verify=False),
            ),
            retriever=retriever,
            combine_docs_chain_kwargs={"prompt": prompt},
            memory=memory,
            return_source_documents=True,
            return_generated_question=True,
            verbose=DEBUG_MODE
        )
        # qa ë³€ìˆ˜ë¥¼ session_stateì— í• ë‹¹
        st.session_state.qa = qa
        
        # ë””ë²„ê¹…ìš© ë¡œê·¸
        if DEBUG_MODE:
            st.write(f"[DEBUG] QA ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # Retrieverë„ session_stateì— í• ë‹¹
        st.session_state.retriever = retriever
    except Exception as e:
        st.error(f"RAG íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        if DEBUG_MODE:
            import traceback
            st.code(traceback.format_exc(), language="python")
        st.stop()
except Exception as e:
    st.error(f"ì•± ì‹¤í–‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    if DEBUG_MODE:
        import traceback
        st.code(traceback.format_exc(), language="python")

# ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ í›„ì† ì§ˆë¬¸ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_follow_up_questions(question, answer):
    """ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ í›„ì† ì§ˆë¬¸ ìƒì„±"""
    try:
        # í›„ì† ì§ˆë¬¸ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìê°€ ì´ì–´ì„œ ë¬¼ì–´ë³¼ ë§Œí•œ ê´€ë ¨ ì§ˆë¬¸ 3ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ì§ˆë¬¸ê³¼ ë‹µë³€ì˜ ë§¥ë½ì„ ìœ ì§€í•˜ê³ , ì‚¬ìš©ìê°€ ë” ì•Œê³  ì‹¶ì–´í•  ë§Œí•œ ë‚´ìš©ì„ ë‹¤ë£¨ëŠ” ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
        
        ì‚¬ìš©ì ì§ˆë¬¸: {question}
        ë‹µë³€: {answer}
        
        ê´€ë ¨ ì§ˆë¬¸ 3ê°œ (ê°„ê²°í•˜ê²Œ):
        """
        
        # ëª¨ë¸ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ ìƒì„±
        response = st.session_state.qa.combine_docs_chain.llm.predict(prompt)
        
        # ìƒì„±ëœ í…ìŠ¤íŠ¸ì—ì„œ ì§ˆë¬¸ ì¶”ì¶œ
        questions = []
        for line in response.strip().split('\n'):
            line = line.strip()
            # ë²ˆí˜¸ ë¶™ì€ í–‰ë§Œ ì¶”ì¶œ (1. 2. 3. ë“±)
            if re.match(r'^\d+\.?\s+', line):
                # ë²ˆí˜¸ ì œê±°í•˜ê³  ì§ˆë¬¸ë§Œ ì¶”ì¶œ
                question = re.sub(r'^\d+\.?\s+', '', line).strip()
                if question and len(question) > 10:
                    questions.append(question)
            
        # ìµœëŒ€ 3ê°œ ì§ˆë¬¸ ë°˜í™˜
        return questions[:3]
    except Exception as e:
        if DEBUG_MODE:
            st.error(f"í›„ì† ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        # ì˜¤ë¥˜ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []
